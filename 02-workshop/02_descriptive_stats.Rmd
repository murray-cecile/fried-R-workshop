---
title: "Basic data cleaning and analysis"
author: "Cecile Murray"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
libs <- c("here", "tidyverse", "magrittr", "knitr", "kableExtra", "janitor")
lapply(libs, library, character.only = TRUE)
```

## Lesson goals

- Introduce key terms and syntax
- Introduce some typical data cleaning concepts and tools
- Introduce basic commands to compute descriptive statistics
- Introduce how to join two datasets

## Terms and syntax

### Key terminology

- Objects: An object is some value or values held in memory, referenced with a name. In R, an object can be a single number, a vector, a dataframe, a function, a plot - pretty much anything. 

- Variable: A variable is an object that stores data. People will also use the word variable to refer to the columns of a dataframe.

- Functions: A function is a set of instructions for performing some computation. Functions are also sometimes called methods.
  - In R, functions are objects. For example, we can write some code that adds 2 and divides by 3 to some number and give that code a name so we can reuse it lots of places (we'll do this next time). 
  - An input value for a function is called an argument. People say they "pass" an object to a function, which "takes" that object as an argument.
  - The output value from a function is a return value. People say a function "returns" some object.  
  - Often, people denote that something is a function by putting parentheses after its name, like so: `mutate()`

### Pipes

One of the most useful parts of the tidyverse comes from the pipe operator, which looks like this: `%>%`. 

Pipes let us chain functions together, passing data frames along from one function to the next without needing to repeat the name of the function. Basically, you're "piping" the output of one function into the next function. Piping exists in many languages and you'll sometimes see it called "method chaining."

Here's an example.

```{r pipes}
# this is the usual assignment arrow
crimes <- read_csv("../data/Crimes_-_2018.csv")

# these are equivalent!
glimpse(crimes)
crimes %>% glimpse() # here we are using a pipe

# here's a reflexive pipe, which basically modifies the original dataframe in place
#   we are piping crimes into the clean_names() function 
#   then assigning the name crimes to the result 
crimes %<>% janitor::clean_names()
```


## Data cleaning

Data often don't come in a format that is immediately ready for analysis. Usually, you'll need to perform some of the following steps, some of which may be familiar from Excel:

- converting variable types: string to numeric and vice versa, dates, etc
- look for missingness
- "recode" variables into useful categories
- reshape the data: convert columns and rows
- look up another dataset

Verbs: mutate, select, filter

### Verbs: mutate

The mutate function allows you to (1) create a new column in your data or (2) transform the data in an existing column.

Let's say we want to convert the district variable from a string into numeric. There's more than one way to do this in R, so again we'll look at the base R way and the tidyverse way:

```{r newvar}
# in base R, we can create a new variable as follows
crimes$district_num <- as.numeric(crimes$district)

# using the tidyverse
crimes %<>% mutate(district_num = as.numeric(district))

# note that we could also do this to transform the district column itself
# crimes %<>% mutate(district = as.numeric(district))

```

Both calls are a single line. Here are some things that are nice about the second way:

- only need to type the name of the dataframe once (helpful if you have many variables)
- no dollar signs, so you can just reference the variable name directly

### Verbs: select

As the name suggests, `select()` lets you select the columns you want to keep in your dataframe. 

The crimes dataset has 23 variables right now, and often datasets will have more. Say we only care about the unique ID, the date, and the type.

```{r select1}
# in the tidyverse, this is really easy:
crimes2 <- crimes %>%
  select(id, date, primary_type)

# it's uglier in base R
crimes2 <- crimes[, c("id", "date", "primary_type")]

```

`select()` is actually really powerful: you can also use it to drop columns, select only columns that contain certain characters or have certain prefixes or suffixes, select only columns with numbers in some range, and much more. Many of these would be much more cumbersome in base R. Here are some examples:

```{r select2}
# tidyverse: drop x and y coordinate fields
crimes2 <- crimes %>% 
  select(-x_coordinate, -y_coordinate)

# base R approach 
names_to_keep <- setdiff(names(crimes),
                         c("x_coordinate", "y_coordinate"))
crimes2 <- crimes[, names_to_keep]

# example of the contains() helper function - can't easily do this in base R
crime_descr <- crimes %>%
  select(contains("description"))

```

### Verbs: filter

The `filter()` function does exactly the same thing as filters in Excel: it filters the rows of your dataframe. 

You give it the logical condition corresponding to the rows you want to keep. If there are two or more conditions your rows need to meet (e.g. arsons in a specific community area), you can separate them with commas. The commas will act like an "and" here.

```{r filter}
# tidyverse way to filter to only the arsons
arson <- crimes %>% 
  filter(primary_type == "ARSON")

# in base R - not a lot of typing but much less clear
arson <- crimes[crimes$primary_type == "ARSON", ]

# tidyverse way to filter to arsons in ward 1
arson_ward1 <- crimes %>% 
  filter(primary_type == "ARSON",
         ward == 1)

# base R equivalent... you can see this gets ugly fast
arson_ward1 <- crimes[crimes$primary_type == "ARSON" & crimes$ward == 1, ]

```


## Descriptive stats

Say your boss asks you for a table giving the counts of each type of crime in Chicago. In Excel, we could use a COUNTIF In R, we use two functions in combination: `group_by()` and `summarize()`.

The first step is to group rows by some category in our data - in this case, the primary type. You give the names of the fields containing those categoies to `group_by()`. 

The next step is to do some summary operation on it - counting the rows in each group. You give `summarize()` the name of the variable you want to create, followed by an equals sign, followed by the expression needed to generate that variable.

```{r gb_ct}
# we use the n() function inside summarize() to count rows
crimes_ct <- crimes %>% 
  group_by(primary_type) %>% 
  summarize(count = n())

# we can also group by multiple categories
crimes_ct2 <- crimes %>% 
  group_by(primary_type, arrest) %>% 
  summarize(count = n())

# bonus: sort by number of crimes 
crimes_ct %<>% arrange(count) # in ascending order
crimes_ct %<>% arrange(-count) # in descending order

```

You can plug in many different summary measures. Here are some examples:

```{r summaries}
# count of arrests by type
crimes_arrest_ct <- crimes %>% 
  group_by(primary_type) %>% 
  summarize(arrests = sum(arrest, na.rm = TRUE))

# mean ward by crime type (nonsensical example)
crimes_ward <- crimes %>% 
  group_by(primary_type) %>% 
  summarize(mean_ward = mean(ward, na.rm = TRUE))

# example with multiple columns
crimes_ward <- crimes %>% 
  group_by(primary_type) %>% 
  summarize(mean_ward = mean(ward, na.rm = TRUE),
            sum_ward = sum(ward, na.rm = TRUE))


```

## Merging datasets

Let's say your supervisor wants a table showing how many crimes occurred in each neighborhood.

Easy, we've already done this:

```{r nhood_ct1}
crimes_nhood <- crimes %>% 
  group_by(community_area) %>% 
  summarize(count = n())

# let's look at the result
head(crimes_nhood)
```

There's a problem: we don't have the names of community areas in this dataset, only a numeric identifier. Your boss doesn't know what those identifiers refer to!

What to do?

We need another table listing community area names and numeric identifiers. We can get this from the city data portal.

In Excel, we could then do a VLOOKUP. In R, we're going to **join** in another table to effectively add in an additional column. We will join on the community area field, using that unique ID number to link the two tables.

```{r join_comm_areas}
# first read in the file
chicago_nhoods <- read_csv("../data/CommAreas.csv")
glimpse(chicago_nhoods)

# drop extraneous fields
chicago_nhoods %<>% select(COMMUNITY, AREA_NUMBE) 

# now do a left join
crimes_nhood <- crimes %>% 
  group_by(community_area) %>% 
  summarize(count = n()) %>% 
  inner_join(chicago_nhoods, 
            by = c("community_area" = "AREA_NUMBE")) 
head(crimes_nhood) 

# some clean-up so the resulting table has only the needed info in it and
# is sorted alphabetically by community area name
crimes_nhood %<>% select(COMMUNITY, count) %>% 
  arrange(COMMUNITY)
head(crimes_nhood)

# alternatively, maybe it's more informative to sort by # crimes
crimes_nhood %<>% arrange(-count)
head(crimes_nhood)
```

### Other kinds of joins

We did a inner join here, but there are several kinds of joins:

- inner join: keep only rows that have a match in both tables

- left join: keep all rows in left table, discard rows in right table with no match

- right join: keep all rows in right table, discard rows in left table with no match

- full join: keep all rows, regardless of whether there is a match

- anti join: keep all rows from left table that *don't* match any rows in the right table

- semi join: keep all rows from left table that have matches in right (like a left join), but only keep the columns from the left table.\footnote{Sounds weird, but it's equivalent to filtering out rows that don't appear in another table, like df %>% filter(id %in% df2$id). This is a common operation.}

Here's why that matters.

```{r left_join_ex}
crimes_nhood <- crimes %>% 
  group_by(community_area) %>% 
  summarize(count = n()) %>% 
  left_join(chicago_nhoods, 
            by = c("community_area" = "AREA_NUMBE")) 
head(crimes_nhood) # note the NA! what does that tell us?
```

### Bonus content: spatial joins

It can be extremely helpful to join tables based on geography too. 

For example, these crimes have a latitude and longitude. Suppose we wanted a count of crimes by some kind of custom geography. If we could draw that as a polygon and then count the points inside, we'd be set. We would have performed a point-in-polygon join.

For many years, people primarily used (expensive, often clunky) ArcGIS software for this kind of thing, but the `sf` package in R has made performing these operations in R as easy as regular joins.  

## Teaser for next time: viz

By now you're probably tired of staring at tables and you want to make a chart, just like you would in Excel. There's a package for that: `ggplot2`.

We will spend all of next time working on data viz, but as a teaser, here's how to make a bar chart of the crime counts.

```{r bar_chart}
# simplest formation, but hard to read
crimes_ct %>% 
  ggplot(aes(x = primary_type,
             y = count)) +
  geom_col() 

# let's just look at a few types of crime
crimes_ct %>%
  filter(primary_type %in% c("THEFT",
                             "BATTERY",
                             "CRIMINAL DAMAGE",
                             "ASSAULT")) %>% 
  ggplot(aes(x = primary_type,
             y = count)) +
  geom_col() 
```


